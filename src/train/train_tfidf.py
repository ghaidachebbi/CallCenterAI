# train_tfidf.py
import pandas as pd
import re
import string
import nltk
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import LinearSVC
from sklearn.pipeline import Pipeline
from sklearn.calibration import CalibratedClassifierCV
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
import joblib
import mlflow

# T√©l√©charger les stopwords la premi√®re fois
nltk.download('stopwords')

# === 1Ô∏è‚É£ Fonction de nettoyage du texte ===
def clean_text(text):
    if not isinstance(text, str):
        return ""
    # Minuscule
    text = text.lower()
    # Supprimer les URLs
    text = re.sub(r'http\S+|www\S+|https\S+', '', text)
    # Supprimer la ponctuation
    text = text.translate(str.maketrans('', '', string.punctuation))
    # Supprimer les chiffres
    text = re.sub(r'\d+', '', text)
    # Supprimer les mots vides (stopwords) mais garder certains mots cl√©s
    stop_words = set(stopwords.words('english'))
    keywords_keep = {"invoice", "payment", "subscription", "charge", "billing"}
    text = ' '.join([word for word in text.split() if word not in stop_words or word in keywords_keep])
    # Supprimer les espaces multiples
    text = re.sub(r'\s+', ' ', text).strip()
    return text

# === 2Ô∏è‚É£ Charger le dataset ===
df = pd.read_csv("data/tickets.csv")

# V√©rification des colonnes
if 'Document' not in df.columns or 'Topic_group' not in df.columns:
    raise ValueError("‚ùå Les colonnes 'Document' et 'Topic_group' doivent exister dans data/tickets.csv")

# Nettoyage du texte
df['clean_text'] = df['Document'].apply(clean_text)

texts = df['clean_text'].tolist()
labels = df['Topic_group'].tolist()

# === 3Ô∏è‚É£ Division train/test ===
X_train, X_test, y_train, y_test = train_test_split(
    texts, labels, test_size=0.2, random_state=42
)

# === 4Ô∏è‚É£ Pipeline TF-IDF + SVM calibr√© ===
pipeline = Pipeline([
    ('tfidf', TfidfVectorizer(max_features=10000, ngram_range=(1,3))),
    ('svc', CalibratedClassifierCV(LinearSVC()))
])

# === 5Ô∏è‚É£ Entra√Ænement et suivi avec MLflow ===
mlflow.start_run()

pipeline.fit(X_train, y_train)

# === 6Ô∏è‚É£ √âvaluation ===
y_pred = pipeline.predict(X_test)
report = classification_report(y_test, y_pred, output_dict=True)
print("üìä Rapport de classification :")
print(report)

# Log des m√©triques principales dans MLflow
mlflow.log_metrics({
    "accuracy": report["accuracy"],
    "f1_macro": report["macro avg"]["f1-score"]
})

mlflow.end_run()

# === 7Ô∏è‚É£ Sauvegarde du mod√®le ===
joblib.dump(pipeline, "models/tfidf_svm.pkl")

print("\n‚úÖ Mod√®le entra√Æn√© et sauvegard√© dans models/tfidf_svm.pkl")
